{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0c63ba6e2e28f3b2\n",
      "Reusing dataset json (/home/liam/.cache/huggingface/datasets/json/default-0c63ba6e2e28f3b2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "100%|██████████| 3/3 [00:00<00:00, 445.68it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data from the policyqa folder\n",
    "dataset = datasets.load_dataset('json', data_files={'train': 'policyqa/train.json', 'dev': 'policyqa/dev.json', 'test': 'policyqa/test.json'}, field='data') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': 'create and deliver personalized promotions, including by combining your Personal Information with Other Information, such as the amounts and types of bookings or itineraries you make and discounts or benefits you use', 'index': 11, 'qas': [{'answers': [{'answer_start': 67, 'text': 'your Personal Information'}], 'id': 'wo1uc0blyt1k5tsx', 'question': 'What type of information about me does the website collect?', 'type': 'First Party Collection/Use|||Personal Information Type|||Generic personal information'}, {'answers': [{'answer_start': 0, 'text': 'create and deliver personalized promotions'}], 'id': 'vycw7xem04dd090w', 'question': 'For what purpose do you use my data?', 'type': 'First Party Collection/Use|||Purpose|||Basic service/feature'}, {'answers': [{'answer_start': 57, 'text': 'combining your Personal Information with Other Information'}], 'id': '78981ujzwheh9wvj', 'question': 'Does the company collect my personal information?', 'type': 'First Party Collection/Use|||Personal Information Type|||Other'}, {'answers': [{'answer_start': 0, 'text': 'create and deliver personalized promotions'}], 'id': '7ccp9n9ixa0l0403', 'question': 'Will they use the data collected from me?', 'type': 'First Party Collection/Use|||Does/Does Not|||Does'}, {'answers': [{'answer_start': 0, 'text': 'create and deliver personalized promotions'}], 'id': 'nbx18kgyk68hsenj', 'question': 'Will you use my information for marketing or promotional services?', 'type': 'First Party Collection/Use|||Purpose|||Marketing'}, {'answers': [{'answer_start': 98, 'text': 'Other Information, such as the amounts and types of bookings or itineraries you make and discounts or benefits you use'}], 'id': 'm2esd7lf0zstp6kn', 'question': 'What types of user profile information does the company collect?', 'type': 'First Party Collection/Use|||Personal Information Type|||User profile'}], 'summary': ['The site collects your generic personal information for a basic service or feature. Collection happens in an unspecified way.', 'The site collects your unspecified information for advertising. Collection happens in an unspecified way.', 'The site collects your user profile for a basic service or feature. Collection happens in an unspecified way.', 'The site collects an information type outside of our label scheme for marketing purposes. Collection happens in an unspecified way.']}\n",
      "dict_keys(['title', 'paragraphs'])\n"
     ]
    }
   ],
   "source": [
    "# print the keys of the training dataset\n",
    "print(dataset['test'][0]['paragraphs'][10:11][0])\n",
    "print(dataset['test'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_use_entire_document_as_context(row):\n",
    "    \"\"\"\n",
    "    Convert the paragraphs into documents by:\n",
    "    1. Iteratre over each paragraph in the document (supplied row)\n",
    "    2. Concatenate all of the paragraphs' contexts together to form a single document\n",
    "    3. Update the 'context' field of each paragraph to be the document\n",
    "    4. Update the start of each answer to be the start of the answer in the document\n",
    "    :param row: a row from the dataset representing a single document\n",
    "    :return: the updated dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # join all of the contexts together to form a single document, separating each with a newline\n",
    "    entire_document = '\\n'.join([paragraph['context'] for paragraph in row['paragraphs']])\n",
    "\n",
    "    # the offset relative to the start of the document\n",
    "    context_offset = 0 \n",
    "\n",
    "    for paragraph in row['paragraphs']:\n",
    "        original_context = paragraph['context']\n",
    "        paragraph['context'] = entire_document\n",
    "        for qa in paragraph['qas']:\n",
    "            for answer in qa['answers']:\n",
    "                answer['answer_start'] += context_offset\n",
    "\n",
    "        # update the context offset for the next paragraph\n",
    "        context_offset += len(original_context) + 1 # +1 for the newline character\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def check_answer_offsets(row):\n",
    "    \"\"\"\n",
    "    Check that the answer offsets are correct\n",
    "    :param row: a row from the dataset representing a single document\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    for paragraph in row['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            for answer in qa['answers']:\n",
    "                start = answer['answer_start']\n",
    "                selected_from_context = paragraph['context'][start:start + len(answer['text'])]\n",
    "                actual_text = answer['text']\n",
    "                assert selected_from_context == actual_text, f\"Expected {actual_text} but got {selected_from_context}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/liam/.cache/huggingface/datasets/json/default-0c63ba6e2e28f3b2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-be0d73e610aebd79.arrow\n",
      "Loading cached processed dataset at /home/liam/.cache/huggingface/datasets/json/default-0c63ba6e2e28f3b2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-dec5f827c7192b57.arrow\n",
      "Loading cached processed dataset at /home/liam/.cache/huggingface/datasets/json/default-0c63ba6e2e28f3b2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6ef676e5dcca3aea.arrow\n",
      "100%|██████████| 75/75 [00:01<00:00, 66.61ex/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 127.92ex/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 77.21ex/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 75\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_dataset = dataset.map(make_dataset_use_entire_document_as_context)\n",
    "\n",
    "long_dataset.map(check_answer_offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
